{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow keras pandas matplotlib scikit-learn\n",
        "!pip install tensorflow==2.15.0 keras==2.15.0 pandas==2.0.3 matplotlib==3.9.1 scikit-learn==1.5.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVc_yBzE4J_o",
        "outputId": "2baaa6d1-7216-413c-f1f7-cdc1483f7663"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Successfully uninstalled tensorflow-2.15.0\n",
            "Found existing installation: keras 2.15.0\n",
            "Uninstalling keras-2.15.0:\n",
            "  Successfully uninstalled keras-2.15.0\n",
            "Found existing installation: pandas 2.0.3\n",
            "Uninstalling pandas-2.0.3:\n",
            "  Successfully uninstalled pandas-2.0.3\n",
            "Found existing installation: matplotlib 3.9.1\n",
            "Uninstalling matplotlib-3.9.1:\n",
            "  Successfully uninstalled matplotlib-3.9.1\n",
            "Found existing installation: scikit-learn 1.5.1\n",
            "Uninstalling scikit-learn-1.5.1:\n",
            "  Successfully uninstalled scikit-learn-1.5.1\n",
            "Collecting tensorflow==2.15.0\n",
            "  Using cached tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "Collecting keras==2.15.0\n",
            "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "Collecting pandas==2.0.3\n",
            "  Using cached pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "Collecting matplotlib==3.9.1\n",
            "  Using cached matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "Collecting scikit-learn==1.5.1\n",
            "  Using cached scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (3.1.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Installing collected packages: keras, scikit-learn, pandas, matplotlib, tensorflow\n",
            "Successfully installed keras-2.15.0 matplotlib-3.9.1 pandas-2.0.3 scikit-learn-1.5.1 tensorflow-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # Basic packages for creating dataframes and loading dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # Package for visualization\n",
        "import re # importing package for Regular expression operations\n",
        "from sklearn.model_selection import train_test_split # Package for splitting the data\n",
        "from sklearn.preprocessing import LabelEncoder # Package for conversion of categorical to Numerical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # Tokenization\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # Add zeros or crop based on the length\n",
        "from tensorflow.keras.models import Sequential # Sequential Neural Network\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D # For layers in Neural Network\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the dataset as a Pandas DataFrame\n",
        "path_to_csv = '/content/sample_data/Sentiment.csv'\n",
        "dataset = pd.read_csv(path_to_csv, header=0)\n",
        "\n",
        "# Select only the necessary columns 'text' and 'sentiment'\n",
        "mask = dataset.columns.isin(['text', 'sentiment'])\n",
        "data = dataset.loc[:, mask]\n",
        "\n",
        "# Keeping only the necessary columns\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ') # Removing Retweets\n",
        "\n",
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ') # Maximum words is 2000 to tokenize sentence\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values) # Taking values to feature matrix\n",
        "X = pad_sequences(X) # Padding the feature matrix\n",
        "\n",
        "embed_dim = 128 # Dimension of the Embedded layer\n",
        "lstm_out = 196 # Long short-term memory (LSTM) layer neurons\n",
        "\n",
        "def createmodel():\n",
        "    model = Sequential() # Sequential Neural Network\n",
        "    model.add(Embedding(max_features, embed_dim, input_length = X.shape[1])) # input dimension 2000 Neurons, output dimension 128 Neurons\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) # Drop out 20%, 196 output Neurons, recurrent dropout 20%\n",
        "    model.add(Dense(3, activation='softmax')) # 3 output neurons[positive, Neutral, Negative], softmax as activation\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy']) # Compiling the model\n",
        "    return model\n",
        "\n",
        "labelencoder = LabelEncoder() # Applying label Encoding on the label matrix\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment']) # Fitting the model\n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42) # 67% training data, 33% test data split\n",
        "\n",
        "batch_size = 32 # Batch size 32\n",
        "model = createmodel() # Function call to Sequential Neural Network\n",
        "model.fit(X_train, Y_train, epochs=1, batch_size=batch_size, verbose=2) # verbose the higher, the more messages\n",
        "score, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=batch_size) # evaluating the model\n",
        "print(score)\n",
        "print(acc)\n",
        "print(model.metrics_names) # metrics of the model\n",
        "print(integer_encoded)\n",
        "print(data['sentiment'])\n",
        "\n",
        "# Predicting on the text data\n",
        "sentence = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing.@realDonaldTrump']\n",
        "sentence = tokenizer.texts_to_sequences(sentence) # Tokenizing the sentence\n",
        "sentence = pad_sequences(sentence, maxlen=X.shape[1], dtype='int32', value=0) # Padding the sentence\n",
        "sentiment_probs = model.predict(sentence, batch_size=1, verbose=2)[0] # Predicting the sentence text\n",
        "sentiment = np.argmax(sentiment_probs)\n",
        "\n",
        "print(sentiment_probs)\n",
        "if sentiment == 0:\n",
        "    print(\"Neutral\")\n",
        "elif sentiment == 1:\n",
        "    print(\"Negative\")\n",
        "else:\n",
        "    print(\"Positive\")\n",
        "\n",
        "# Custom wrapper for Keras model\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class CustomKerasClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, build_fn=None, epochs=1, batch_size=32, verbose=1, **sk_params):\n",
        "        self.build_fn = build_fn\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.verbose = verbose\n",
        "        self.sk_params = sk_params\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y, **kwargs):\n",
        "        self.model = self.build_fn()\n",
        "        return self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose, **kwargs)\n",
        "\n",
        "    def predict(self, X, **kwargs):\n",
        "        return self.model.predict(X, **kwargs)\n",
        "\n",
        "    def predict_proba(self, X, **kwargs):\n",
        "        return self.model.predict(X, **kwargs)\n",
        "\n",
        "    def score(self, X, y, **kwargs):\n",
        "        _, accuracy = self.model.evaluate(X, y, verbose=0)\n",
        "        return accuracy\n",
        "\n",
        "# Use the custom Keras classifier\n",
        "model = CustomKerasClassifier(build_fn=createmodel, verbose=2)\n",
        "batch_size = [10, 20, 40]\n",
        "epochs = [1, 2]\n",
        "param_grid = {'batch_size': batch_size, 'epochs': epochs}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caJyiQ1P6O_2",
        "outputId": "b13fb345-954c-44a5-bd5c-633f3ce5c4c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-6d10c9e89d21>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(lambda x: x.lower())\n",
            "<ipython-input-10-6d10c9e89d21>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 - 46s - loss: 0.8224 - accuracy: 0.6441 - 46s/epoch - 159ms/step\n",
            "144/144 - 3s - loss: 0.7604 - accuracy: 0.6654 - 3s/epoch - 20ms/step\n",
            "0.7604355216026306\n",
            "0.6653560400009155\n",
            "['loss', 'accuracy']\n",
            "[1 2 1 ... 2 0 2]\n",
            "0         Neutral\n",
            "1        Positive\n",
            "2         Neutral\n",
            "3        Positive\n",
            "4        Positive\n",
            "           ...   \n",
            "13866    Negative\n",
            "13867    Positive\n",
            "13868    Positive\n",
            "13869    Negative\n",
            "13870    Positive\n",
            "Name: sentiment, Length: 13871, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ad0db684310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - 259ms/epoch - 259ms/step\n",
            "[0.6961828  0.14821675 0.1556004 ]\n",
            "Neutral\n",
            "744/744 - 93s - loss: 0.8199 - accuracy: 0.6455 - 93s/epoch - 125ms/step\n",
            "744/744 - 97s - loss: 0.8228 - accuracy: 0.6421 - 97s/epoch - 130ms/step\n",
            "744/744 - 93s - loss: 0.8218 - accuracy: 0.6493 - 93s/epoch - 125ms/step\n",
            "744/744 - 94s - loss: 0.8286 - accuracy: 0.6414 - 94s/epoch - 126ms/step\n",
            "744/744 - 94s - loss: 0.8147 - accuracy: 0.6502 - 94s/epoch - 126ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 98s - loss: 0.8284 - accuracy: 0.6457 - 98s/epoch - 132ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 92s - loss: 0.6847 - accuracy: 0.7113 - 92s/epoch - 123ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 94s - loss: 0.8254 - accuracy: 0.6421 - 94s/epoch - 126ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 91s - loss: 0.6763 - accuracy: 0.7112 - 91s/epoch - 122ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 89s - loss: 0.8237 - accuracy: 0.6450 - 89s/epoch - 120ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 90s - loss: 0.6755 - accuracy: 0.7116 - 90s/epoch - 121ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 97s - loss: 0.8239 - accuracy: 0.6430 - 97s/epoch - 131ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 93s - loss: 0.6737 - accuracy: 0.7170 - 93s/epoch - 126ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 91s - loss: 0.8178 - accuracy: 0.6487 - 91s/epoch - 122ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 91s - loss: 0.6657 - accuracy: 0.7185 - 91s/epoch - 122ms/step\n",
            "372/372 - 54s - loss: 0.8349 - accuracy: 0.6426 - 54s/epoch - 145ms/step\n",
            "372/372 - 55s - loss: 0.8274 - accuracy: 0.6411 - 55s/epoch - 147ms/step\n",
            "372/372 - 55s - loss: 0.8271 - accuracy: 0.6464 - 55s/epoch - 147ms/step\n",
            "372/372 - 51s - loss: 0.8333 - accuracy: 0.6397 - 51s/epoch - 138ms/step\n",
            "372/372 - 57s - loss: 0.8265 - accuracy: 0.6418 - 57s/epoch - 153ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 54s - loss: 0.8348 - accuracy: 0.6473 - 54s/epoch - 145ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 53s - loss: 0.6786 - accuracy: 0.7147 - 53s/epoch - 141ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 51s - loss: 0.8221 - accuracy: 0.6481 - 51s/epoch - 136ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 51s - loss: 0.6802 - accuracy: 0.7132 - 51s/epoch - 136ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 55s - loss: 0.8315 - accuracy: 0.6387 - 55s/epoch - 147ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 52s - loss: 0.6815 - accuracy: 0.7151 - 52s/epoch - 140ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 57s - loss: 0.8280 - accuracy: 0.6397 - 57s/epoch - 152ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 51s - loss: 0.6709 - accuracy: 0.7130 - 51s/epoch - 138ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 53s - loss: 0.8381 - accuracy: 0.6385 - 53s/epoch - 144ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 49s - loss: 0.6746 - accuracy: 0.7116 - 49s/epoch - 132ms/step\n",
            "186/186 - 33s - loss: 0.8493 - accuracy: 0.6321 - 33s/epoch - 177ms/step\n",
            "186/186 - 35s - loss: 0.8428 - accuracy: 0.6367 - 35s/epoch - 186ms/step\n",
            "186/186 - 36s - loss: 0.8437 - accuracy: 0.6357 - 36s/epoch - 192ms/step\n",
            "186/186 - 33s - loss: 0.8503 - accuracy: 0.6351 - 33s/epoch - 178ms/step\n",
            "186/186 - 35s - loss: 0.8431 - accuracy: 0.6366 - 35s/epoch - 187ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 35s - loss: 0.8579 - accuracy: 0.6297 - 35s/epoch - 186ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 31s - loss: 0.6950 - accuracy: 0.7006 - 31s/epoch - 167ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 33s - loss: 0.8357 - accuracy: 0.6404 - 33s/epoch - 176ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 31s - loss: 0.6883 - accuracy: 0.7062 - 31s/epoch - 168ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 35s - loss: 0.8452 - accuracy: 0.6321 - 35s/epoch - 187ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 30s - loss: 0.6822 - accuracy: 0.7117 - 30s/epoch - 162ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 37s - loss: 0.8445 - accuracy: 0.6344 - 37s/epoch - 196ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 30s - loss: 0.6826 - accuracy: 0.7061 - 30s/epoch - 164ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 33s - loss: 0.8384 - accuracy: 0.6354 - 33s/epoch - 178ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 31s - loss: 0.6760 - accuracy: 0.7176 - 31s/epoch - 165ms/step\n",
            "Epoch 1/2\n",
            "233/233 - 45s - loss: 0.8322 - accuracy: 0.6394 - 45s/epoch - 194ms/step\n",
            "Epoch 2/2\n",
            "233/233 - 39s - loss: 0.6823 - accuracy: 0.7097 - 39s/epoch - 169ms/step\n",
            "Best: 0.678682 using {'batch_size': 40, 'epochs': 2}\n"
          ]
        }
      ]
    }
  ]
}